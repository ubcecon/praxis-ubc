{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A visual introduction to fundamental modern machine Learning\n",
        "\n",
        "*Yash Mali*  \n",
        "2025-07-24"
      ],
      "id": "ce11a65d-f60e-43da-91e2-7393f9b4d9e0"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-25T03:28:05.891928Z",
          "start_time": "2025-08-25T03:28:05.515708Z"
        },
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# from graphviz import Digraph\n",
        "from IPython.display import display\n",
        "from ipywidgets import interact, FloatSlider\n",
        "np.random.seed(19_750)"
      ],
      "id": "bc40c690"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is Deep Learning, Machine Learning, and Artificial Intelligence?\n",
        "\n",
        "<img src=\"https://media.calibraint.com/calibraint-wordpress/wp-content/uploads/2023/08/10063115/Difference-between-AI-ML-Neural-Network-and-Deep-Learning-2048x1204.jpg\" alt=\"AI, ML, DL\" style=\"max-width:80%; height:auto;\"></img>\n",
        "\n",
        "A Simple History of AI In the 1950s, scientists dreamed of building\n",
        "machines that could think and learn like humans. They created early\n",
        "models called neural networks, inspired by how the brain works. One of\n",
        "the first, called the Perceptron, was built by Frank Rosenblatt. But\n",
        "back then, computers were too slow, and there wasn’t enough data to make\n",
        "these systems work well. So, researchers moved on to simpler methods,\n",
        "largely ignoring neural networks.\n",
        "\n",
        "In 2012, everything changed with a breakthrough called AlexNet. It was a\n",
        "large neural network that could look at pictures and recognize objects\n",
        "(like cats, dogs and cars etc.) better than anything before. It was\n",
        "taught how to recognize images very efficiently and which allowed it to\n",
        "see millions of images and learning how to recognize patterns, stitch\n",
        "them together, and make predictions.\n",
        "\n",
        "<img src=\"https://viso.ai/wp-content/uploads/2024/02/imagenet-winners-by-year.jpg\" alt=\"AI, ML, DL\" style=\"max-width:80%; height:auto;\"></img>\n",
        "\n",
        "In 2017, another big leap happened with the invention of Transformers.\n",
        "These systems could understand very long sequences (like language) at\n",
        "once, making them great at tasks like writing, translating, and\n",
        "summarizing text. This is the technology behind tools like ChatGPT,\n",
        "which can chat, write stories, or even help with coding.\n",
        "\n",
        "## What makes AI good at its job?"
      ],
      "id": "d5e26fc8-0c64-4079-9075-abaac67c65d0"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-18T06:45:34.951780Z",
          "start_time": "2025-08-18T06:45:34.899540Z"
        },
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Generate 20 random x values\n",
        "x = np.linspace(0, 10, 20)\n",
        "\n",
        "# Compute y values with some noise\n",
        "y = x**2 + np.random.normal(0, 5, x.shape)\n",
        "\n",
        "# Plot the points using seaborn with slightly bigger points\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x=x, y=y, s=100, alpha=0.6, label='Data')\n",
        "plt.title('Social media followers vs Engagement')\n",
        "plt.xlabel('X (Followers in thousands)')\n",
        "plt.ylabel('Y (Engagement in thousands)')\n",
        "plt.show()"
      ],
      "id": "67b2cc6c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a plot of social media followers vs engagement. Lets say you\n",
        "want to predict engagement based on followers."
      ],
      "id": "5a03621a-39ac-41ec-ac23-6da89b45c708"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-18T06:45:37.222876Z",
          "start_time": "2025-08-18T06:45:37.166930Z"
        },
        "editable": true,
        "slideshow": {
          "slide_type": ""
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "degree = 2\n",
        "# Fit a polynomial of given degree to the data using numpy\n",
        "coeffs = np.polyfit(x, y, degree)\n",
        "\n",
        "# Compute predicted y values\n",
        "y_pred_2 = np.polyval(coeffs, x)\n",
        "\n",
        "# Plot the original data and the fitted polynomial\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x=x, y=y, s=100, alpha=0.6, label='Data')\n",
        "plt.plot(x, y_pred_2, color='red', label=f'Degree {degree} Fit')\n",
        "plt.title('Social media followers vs Engagement')\n",
        "plt.xlabel('X (Followers in thousands)')\n",
        "plt.ylabel('Y (Engagement in thousands)')\n",
        "plt.show()"
      ],
      "id": "fba59e20"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This red line “fit” to the data"
      ],
      "id": "517c3b81-ab56-4794-8ff7-bb60d2cdeedc"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-18T06:45:57.878842Z",
          "start_time": "2025-08-18T06:45:57.825654Z"
        }
      },
      "outputs": [],
      "source": [
        "degree = 20\n",
        "\n",
        "# Fit a polynomial of given degree to the data using numpy\n",
        "coeffs = np.polyfit(x, y, degree)\n",
        "# Compute predicted y values\n",
        "y_pred_15 = np.polyval(coeffs, x)\n",
        "\n",
        "# Plot the original data and the fitted polynomial\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x=x, y=y, s=100, alpha=0.6, label='Data')\n",
        "plt.plot(x, y_pred_15, color='orange', label=f'Degree {degree} Fit')\n",
        "plt.title('Social media followers vs Engagement')\n",
        "plt.xlabel('X (Followers in thousands)')\n",
        "plt.ylabel('Y (Engagement in thousands)')\n",
        "plt.show()"
      ],
      "id": "e88730f9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This orange line “fit” to the data"
      ],
      "id": "2ebcc5e8-36d7-4557-84b8-7d891b04c6e6"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-18T06:46:08.296269Z",
          "start_time": "2025-08-18T06:46:08.240675Z"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x=x, y=y, s=100, alpha=0.6, label='Data')\n",
        "plt.plot(x, y_pred_15, color='orange', label=f'Degree {15} Fit')\n",
        "plt.plot(x, y_pred_2, color='red', label=f'Degree {2} Fit')\n",
        "plt.title('Social media followers vs Engagement')\n",
        "plt.xlabel('X (Followers in thousands)')\n",
        "plt.ylabel('Y (Engagement in thousands)')\n",
        "plt.show()"
      ],
      "id": "d8608911"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What is better?\n",
        "\n",
        "The red line *seems* better, but the orange line has lower error since\n",
        "it goes directly through ALL points.\n",
        "\n",
        "Say you put a point between some of the blue dots? Is the orange line\n",
        "more likely to predict a better position for the points or the red?\n",
        "\n",
        "-   No! The red line generalizes to points that don’t exist in the plot\n",
        "    much better.\n",
        "\n",
        "What about if you add points to the left and right of the existing\n",
        "points?\n",
        "\n",
        "-   The red line does better again for unseen points.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "To prevent your model from memorizing your data, you intentionally split\n",
        "your data into 2. **The training data and testing data.** The test data\n",
        "should not influence training in any way.\n",
        "\n",
        "Credit - CPSC 330\n",
        "<img src=\"https://ubc-cs.github.io/cpsc330-2024W1/_media/train-test-split.png\" alt=\"AI, ML, DL\" width=\"750\">\n",
        "\n",
        "Key Takeaways\n",
        "\n",
        "-   Your model needs to be able to generalize.\n",
        "-   Your model should not blindly memorize the data it is given. Eg.\n",
        "    force its way through every point.\n",
        "-   The test data should not influence training in any way.\n",
        "\n",
        "This is the fundamental rule of learning.\n",
        "\n",
        "Example:\n",
        "\n",
        "Say your vision model to drive self-driving cars is trained with lots of\n",
        "videos from Los Angeles (Now you drive to Vancouver and realize that\n",
        "your system works a lot worse. One reason for this is that the model\n",
        "**is too used to** the LA data.\n",
        "\n",
        "In reality, self-driving cars are trained on data from all types of\n",
        "cities, suburbs, and rural areas, as well as in all driving conditions\n",
        "and weather. **But** when highly unexpected things happen (like\n",
        "sandstorms or forest fires that make the sky orange), these systems\n",
        "perform worse.\n",
        "\n",
        "<img src=\"https://specials-images.forbesimg.com/imageserve/5f5d987fd704a8411dbcd758/Red-Orange-Skies-from-the-Northern-California-Wildfires-Blanket-San-Francisco-Bay/960x0.jpg?cropX1=979&cropX2=5000&cropY1=312&cropY2=3097\" alt=\"AI, ML, DL\" width=\"750\">\n",
        "\n",
        "*TLDR;* **Your predictor should generalize and find the underlying\n",
        "pattern not memorize that data it has seen like a puppet.**\n",
        "\n",
        "## Neural Networks\n",
        "\n",
        "### Example 1"
      ],
      "id": "b629c027-3f90-49e6-acd5-c0cc5d64cfcc"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-18T06:59:06.219360Z",
          "start_time": "2025-08-18T06:59:06.158079Z"
        }
      },
      "outputs": [],
      "source": [
        "x = np.linspace(1, 50, 100)\n",
        "# Generate y values for -log(x) with noise\n",
        "y_neg_log = np.log(x) + np.random.normal(scale=0.1, size=x.shape)\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x, y_neg_log, label='Data', color='red', s=75, alpha=0.6)\n",
        "plt.title('Years since 1960 vs Population of a city (in millions)')\n",
        "plt.xlabel('X (Years since 1960)')\n",
        "plt.ylabel('Y (Population in millions)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fd955fe4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We cannot draw a line through this data."
      ],
      "id": "447df2fc-a5ad-4f98-b08a-0b027e23804c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-18T08:21:51.069824Z",
          "start_time": "2025-08-18T08:21:50.952571Z"
        }
      },
      "outputs": [],
      "source": [
        "# Original data\n",
        "x = np.linspace(1, 50, 100)\n",
        "y_neg_log = np.log(x) + np.random.normal(scale=0.1, size=x.shape)\n",
        "\n",
        "# Apply a square root transformation to x\n",
        "x_transformed = np.sqrt(x)\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x_transformed, y_neg_log, label='Stretched Data', color='blue', s=75, alpha=0.6)\n",
        "plt.title('Years since 1960 vs Population of a city (in millions)')\n",
        "plt.xlabel('$\\sqrt{X}$ (Years since 1960)')\n",
        "plt.ylabel('Y (Population in millions)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "f6ece92d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we compressed the X axis and made the data **easier to draw a line\n",
        "through**."
      ],
      "id": "31e547f6-25d5-455c-8e39-6f161d46e5a3"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-25T03:28:13.139939Z",
          "start_time": "2025-08-25T03:28:13.015413Z"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Original data\n",
        "x = np.linspace(1, 50, 100)\n",
        "y_neg_log = np.log(x) + np.random.normal(scale=0.1, size=x.shape)\n",
        "\n",
        "# Apply a square root transformation to x\n",
        "x_transformed = np.sqrt(x).reshape(-1, 1)\n",
        "\n",
        "# Fit Ridge regression\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(x_transformed, y_neg_log)\n",
        "y_pred = ridge.predict(x_transformed)\n",
        "\n",
        "# Create the scatter plot + ridge line\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(x_transformed, y_neg_log, label='Stretched Data', color='blue', s=75, alpha=0.6)\n",
        "plt.plot(x_transformed, y_pred, color='red', linewidth=2, label='Ridge Regression Line')\n",
        "plt.title('Years since 1960 vs Population of a city (in millions)')\n",
        "plt.xlabel('X (Years since 1960)')\n",
        "plt.ylabel('Y (Population in millions) COMPRESSED')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "6dac0903"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is what neural networks do. They make it easier to draw a line\n",
        "through or draw a line separating the data. We will use another example\n",
        "to make it clearer.\n",
        "\n",
        "Neural networks facilitate the **“Make the data easier to work with”**\n",
        "step. They do so by learning the transformation needed to do so by\n",
        "looking at the data.\n",
        "\n",
        "### Example 2 and what do models learn?\n",
        "\n",
        "**Another example where we classify data.**\n",
        "\n",
        "Say we have data that has coordinates (longitude and latitude), and the\n",
        "data are people. You want to classify the people based on “living in\n",
        "urban areas” and “living in rural areas”. This data can look like the\n",
        "following:"
      ],
      "id": "4b66ad07-a3cb-4505-86e6-12415e634d34"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "rng = np.random.default_rng(19_750)\n",
        "r_city, r_rural = 2.0, 5.0\n",
        "\n",
        "# Generate \"city\" as a dense filled disk (class 1)\n",
        "n_city = 1000\n",
        "theta_c = 2 * np.pi * rng.random(n_city)\n",
        "r_c = r_city * np.sqrt(rng.random(n_city))  # uniform over area\n",
        "x_c = r_c * np.cos(theta_c)\n",
        "y_c = r_c * np.sin(theta_c)\n",
        "\n",
        "# Generate \"rural\" as a sparse thin ring (class 0)\n",
        "n_rural = 250\n",
        "theta_r = 2 * np.pi * rng.random(n_rural)\n",
        "r_r = r_rural + rng.normal(0, 0.35, n_rural)  # thin ring\n",
        "x_r = r_r * np.cos(theta_r)\n",
        "y_r = r_r * np.sin(theta_r)\n",
        "\n",
        "# Stack data\n",
        "X = np.vstack([np.c_[x_r, y_r], np.c_[x_c, y_c]])\n",
        "y = np.concatenate([np.zeros(n_rural, dtype=int), np.ones(n_city, dtype=int)])\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Just plot the data (train and test, color by class)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.scatter(Xtr[ytr == 1, 0], Xtr[ytr == 1, 1], s=15, c='gold', edgecolor='k', label='City (train)')\n",
        "plt.scatter(Xtr[ytr == 0, 0], Xtr[ytr == 0, 1], s=15, c='purple', edgecolor='k', label='Rural (train)')\n",
        "plt.scatter(Xte[yte == 1, 0], Xte[yte == 1, 1], s=25, c='gold', edgecolor='k', marker='^', label='City (test)')\n",
        "plt.scatter(Xte[yte == 0, 0], Xte[yte == 0, 1], s=25, c='purple', edgecolor='k', marker='^', label='Rural (test)')\n",
        "plt.legend(loc='best', fontsize=9)\n",
        "plt.title(\"Urban vs Rural Areas Population\")\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "bc1859f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You might want to do this classifying for resource allocation. For\n",
        "example, where should I put more fire stations?\n",
        "\n",
        "Though here, it is just a simple example/demonstration. You cannot draw\n",
        "a line to seperate the 2 polulations."
      ],
      "id": "20d5f830-d7dd-4461-9140-552704eb057d"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-08-25T03:54:10.194939Z",
          "start_time": "2025-08-25T03:54:09.965882Z"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Small neural net (non-linear)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(8, 8), activation='relu', solver='lbfgs', alpha=1e-4, random_state=42, max_iter=2000)\n",
        "mlp.fit(Xtr, ytr)\n",
        "\n",
        "acc_mlp = accuracy_score(yte, mlp.predict(Xte))\n",
        "\n",
        "# Decision boundary visualization for MLP only\n",
        "x_min, x_max = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0\n",
        "y_min, y_max = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 400), np.linspace(y_min, y_max, 400))\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "Z_mlp = mlp.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "cs = ax.contourf(xx, yy, Z_mlp, levels=[0.0, 0.5, 1.0], alpha=0.25, cmap='coolwarm')\n",
        "ax.scatter(Xtr[ytr == 1, 0], Xtr[ytr == 1, 1], s=15, c='gold', edgecolor='k', label='City (train)')\n",
        "ax.scatter(Xtr[ytr == 0, 0], Xtr[ytr == 0, 1], s=15, c='purple', edgecolor='k', label='Rural (train)')\n",
        "ax.scatter(Xte[yte == 1, 0], Xte[yte == 1, 1], s=25, c='gold', edgecolor='k', marker='^', label='City (test)')\n",
        "ax.scatter(Xte[yte == 0, 0], Xte[yte == 0, 1], s=25, c='purple', edgecolor='k', marker='^', label='Rural (test)')\n",
        "ax.set_title(f\"Neural net (MLP) — acc={acc_mlp:.3f}\")\n",
        "ax.set_aspect('equal')\n",
        "ax.legend(loc='upper right', fontsize=8)\n",
        "plt.title(\"Urban vs Rural Areas Population\\nDecision Boundry using a Neural Network\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "52fd113c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What might have the neural network done to classify things correctly?\n",
        "\n",
        "This is a very difficult problem. We only have glimses into what neural\n",
        "networks learn and how they internally represent things.\n",
        "\n",
        "But in this case, we could venture a guess and suggest that the model\n",
        "may be doing something like this:"
      ],
      "id": "0149a133-53de-44dc-a1a3-9c1e073850df"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "rng = np.random.default_rng(19_750)\n",
        "r_city, r_rural = 2.0, 5.0\n",
        "\n",
        "# Generate \"city\" as a dense filled disk (class 1)\n",
        "n_city = 1000\n",
        "theta_c = 2 * np.pi * rng.random(n_city)\n",
        "r_c = r_city * np.sqrt(rng.random(n_city))\n",
        "x_c = r_c * np.cos(theta_c)\n",
        "y_c = r_c * np.sin(theta_c)\n",
        "\n",
        "# Generate \"rural\" as a sparse thin ring (class 0)\n",
        "n_rural = 250\n",
        "theta_r = 2 * np.pi * rng.random(n_rural)\n",
        "r_r = r_rural + rng.normal(0, 0.35, n_rural)\n",
        "x_r = r_r * np.cos(theta_r)\n",
        "y_r = r_r * np.sin(theta_r)\n",
        "\n",
        "# Vertical separation for classes\n",
        "z_c = np.full_like(x_c, 1.5)      # City at height 1.5\n",
        "z_r = np.full_like(x_r, -1.5)     # Rural at height -1.5\n",
        "\n",
        "# Stack data\n",
        "X_city = np.c_[x_c, y_c, z_c]\n",
        "X_rural = np.c_[x_r, y_r, z_r]\n",
        "X = np.vstack([X_rural, X_city])\n",
        "y = np.concatenate([np.zeros(n_rural, dtype=int), np.ones(n_city, dtype=int)])\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1975)\n",
        "\n",
        "# 3D plot with vertical separation\n",
        "fig = plt.figure(figsize=(6, 5))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Train points\n",
        "ax.scatter(Xtr[ytr == 1, 0], Xtr[ytr == 1, 1], Xtr[ytr == 1, 2], s=15, c='gold', edgecolor='k', label='City (train)')\n",
        "ax.scatter(Xtr[ytr == 0, 0], Xtr[ytr == 0, 1], Xtr[ytr == 0, 2], s=15, c='purple', edgecolor='k', label='Rural (train)')\n",
        "\n",
        "# Test points\n",
        "ax.scatter(Xte[yte == 1, 0], Xte[yte == 1, 1], Xte[yte == 1, 2], s=25, c='gold', edgecolor='k', marker='^', label='City (test)')\n",
        "ax.scatter(Xte[yte == 0, 0], Xte[yte == 0, 1], Xte[yte == 0, 2], s=25, c='purple', edgecolor='k', marker='^', label='Rural (test)')\n",
        "\n",
        "# Draw a separating plane between classes (e.g., z=0)\n",
        "xlim = ax.get_xlim()\n",
        "ylim = ax.get_ylim()\n",
        "xx, yy = np.meshgrid(np.linspace(*xlim, 20), np.linspace(*ylim, 20))\n",
        "zz = np.zeros_like(xx)  # Plane at z=0\n",
        "\n",
        "ax.plot_surface(xx, yy, zz, alpha=0.5, color='gray', edgecolor='none')\n",
        "\n",
        "ax.set_title(\"Urban vs Rural Areas Population (3D with vertical class separation)\")\n",
        "ax.set_xlabel(\"X\")\n",
        "ax.set_ylabel(\"Y\")\n",
        "ax.set_zlabel(\"Class (vertical separation)\")\n",
        "ax.view_init(elev=25, azim=30)\n",
        "ax.legend(loc='best', fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "c9f30020"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This could be a good guess (approximately) of what a neural network does\n",
        "to separate between rural and urban populations.\n",
        "\n",
        "So what drives the model to do this? How does **it** decide to do this?\n",
        "\n",
        "### How does the model learn?\n",
        "\n",
        "One thing to note is that we don’t tell the model to do something like\n",
        "this; it decides on its own. This is why we don’t understand how AI\n",
        "works in any practical model. We simply specify the problem.\n",
        "\n",
        "Here, the specification can be “minimize the mistakes in classifying\n",
        "between the 2 populations”. Then you pick the correct parameters (using\n",
        "calculus), and the model has learned to do its job.\n",
        "\n",
        "### Deep Learning\n",
        "\n",
        "Deep learning is simply when you make these geometric decisions in steps\n",
        "rather than all at once this has made models much more practical and\n",
        "powerful\n",
        "\n",
        "**What is the point of this?**\n",
        "\n",
        "-   Model any written language that has ever existed. Translate between\n",
        "    any languages. ChatGPT simply classifies the next word and is able\n",
        "    to reason, help, deceive, and “think”.\n",
        "\n",
        "-   Predict the weather.\n",
        "\n",
        "-   Model any type of music or images, or everything altogether to\n",
        "    create videos.\n",
        "\n",
        "-   Drive cars, move robots, and do surgery (poorly for now).\n",
        "\n",
        "-   Predict the stock market (to some extent). Detect fraud every time\n",
        "    you swipe your credit card.\n",
        "\n",
        "-   Spot cancer, strokes, and blood clots. Discover new drugs and select\n",
        "    genes.\n",
        "\n",
        "## Risks and misuse.\n",
        "\n",
        "**But with all these capabilities come risks.** These can be very\n",
        "broadly characterized into:\n",
        "\n",
        "1.  Risks of misuse.\n",
        "2.  Inherent risks of the model.\n",
        "\n",
        "Some inherent risk can emerge from models being trained on biased\n",
        "(human) data.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Inherent\n",
        "\n",
        "<img src=\"media/noise_adv.png\" style=\"max-width:80%; height:auto;\">\n",
        "\n",
        "Credit - CPSC 340, L35\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Misuse\n",
        "\n",
        "<img src=\"media/doge.png\" style=\"max-width:80%; height:auto;\">\n",
        "\n",
        "Credit - The Independent\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Inherent\n",
        "\n",
        "<img src=\"media/obamna.png\" style=\"max-width:80%; height:auto;\">\n",
        "\n",
        "Credit - CPSC 340, L35\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Inherent\n",
        "\n",
        "<img src=\"media/translate.png\" style=\"max-width:80%; height:auto;\">\n",
        "\n",
        "Credit - CPSC 340, L35\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Misuse\n",
        "\n",
        "<img src=\"media/deepfake.png\" style=\"max-width:80%; height:auto;\">\n",
        "\n",
        "Credit - CPSC 340, L35\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Misuse & Inherent\n",
        "\n",
        "<img src=\"media/resume_amazon.png\" style=\"max-width:80%; height:auto;\">\n",
        "\n",
        "Credit - BBC\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Misuse\n",
        "\n",
        "<img src=\"media/bail.png\" style=\"max-width:80%; height:auto;\">\n",
        "\n",
        "Credit - MIT Technology Review\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "More:\n",
        "\n",
        "-   Automated hacking and scams.\n",
        "-   Giving AI control of a banking/credit database.\n",
        "-   Copyright regulation. AI books, music, and movies that look like\n",
        "    others.\n",
        "-   Using AI to persuade groups of people and communities online.\n",
        "-   And so much more!\n",
        "\n",
        "People will misuse AI, and computer scientists are working on trying to\n",
        "make that harder. But turning models “unsafe” and “harmful” is still\n",
        "very easy to do. For free within ~3 hours for a smaller open version of\n",
        "ChatGPT.\n",
        "\n",
        "For the inherent risks of AI, we need to invest more time and energy\n",
        "into understanding what the models are learning rather than purely\n",
        "focusing on the results or what the models can do.\n",
        "\n",
        "We also need people from different domains to understand, use and play a\n",
        "role in making AI (eg. curating diverse data). In the meantime, we must\n",
        "be careful not to give AI control over systems where its unexpected\n",
        "performance can hurt people (eg, deciding if someone can go to jail)\n",
        "\n",
        "# Bonus: Optimization"
      ],
      "id": "1f2df06f-607c-43da-a742-260c7d28ab02"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "run = False\n",
        "if run:\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from ipywidgets import interact, FloatSlider\n",
        "    \n",
        "    x = np.linspace(-5, 5, 50)\n",
        "    y = 2 * x + 1 + np.random.normal(0, 2, 50)\n",
        "    slopes = np.linspace(-4, 6, 100)\n",
        "    mse = lambda s, i=1.0: np.mean((y - (s * x + i)) ** 2)\n",
        "    mse_vals = [mse(s) for s in slopes]\n",
        "    \n",
        "    contour_slopes = np.linspace(-10, 12, 100)\n",
        "    contour_intercepts = np.linspace(-8, 10, 100)\n",
        "    S, I = np.meshgrid(contour_slopes, contour_intercepts)\n",
        "    Z = np.array([[mse(S[i, j], I[i, j]) for j in range(len(contour_slopes))] for i in range(len(contour_intercepts))])\n",
        "    \n",
        "    def plot(s):\n",
        "        i, m = 1.0, mse(s)\n",
        "        fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
        "        ax[0].plot(slopes, mse_vals)\n",
        "        ax[0].scatter(s, m, color='r')\n",
        "        ax[0].set(title=\"Loss Landscape - MOVE THE SLIDER\", xlabel=\"Parameter\", ylabel=\"Error\")\n",
        "        yp = s * x + i\n",
        "        ax[1].scatter(x, y)\n",
        "        ax[1].plot(x, yp, 'orange')\n",
        "        ax[1].set(title=\"Linear Model\")\n",
        "        cp = ax[2].contour(S, I, Z, 20)\n",
        "        ax[2].scatter(s, i, color='r', marker='x', s=100)\n",
        "        ax[2].set(title=\"Landscape Contour Plot\", xlabel=\"Slope\", ylabel=\"Intercept\")\n",
        "        fig.colorbar(cp, ax=ax[2], label=\"MSE\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    interact(plot, s=FloatSlider(value=2, min=-4, max=6, step=0.1))"
      ],
      "id": "2817da71"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  }
}