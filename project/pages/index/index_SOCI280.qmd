---
title: "SOCI280 - Data and Society"
toc: false
listing:
- id: soci280
  type: grid
  image-placeholder: placeholder_images/placeholder.png
  contents:
    - "../../docs/SOCI-280/soci_280_bert.qmd"
  categories: true
  fields: [image, title, date, description]
  sort-ui: [title, date]
---
## SOCI 280: Suggested Lesson Plan – AI, Text Analysis, and Disinformation

**110-minute Lesson Plan Overview**

### Learning Objectives

By the end of this lesson, students will:

- **Understand and complete sentiment analysis** to detect emotional tone (positive, negative, neutral), and **understand and complete toxicity analysis** to identify harmful or aggressive language (e.g., insults, threats).
- **Introduce concepts in statistical testing** to compare patterns between tweet types and languages (e.g., English vs. Russian).
- **Learn how to work with pretrained LLMs**, interpret model predictions, and use basic statistical methods to answer questions like:
    - Are propagandist tweets more emotionally charged or toxic than normal political tweets?
    - Do they use different rhetorical strategies in different languages?
    - Can we identify signals that indicate a tweet is part of a disinformation campaign?

Through this analysis, we’ll explore various dimensions of AI applications, **critically examining how it can better understand and detect the patterns of disinformation** when working with large amounts of social data.

---

### Materials and Technical Requirements

- **Jupyter notebook** (hosted on the prAxIs UBC website)
- Device with internet access (**laptop preferred**)
- No coding experience required (**familiarity with Python is an asset**)
- Students may **pair up** (groups of 2–3) if device access is limited
- **Group work is encouraged**; students will compare findings

---

### Pre-lesson Checklist

- [ ] Students have completed the reading up to Section 0 (approx. 5–10 minutes)
- [ ] Instructor has loaded and can project the notebook
- [ ] Students reminded to bring a device

---

## Agenda

### 1. Pre-discussion and Brief Lecture (5–10 minutes)

- Discuss **misinformation, disinformation, and propaganda**
- Emphasize the role of digital platforms in their spread
- How researchers detect disinformation
- Consider influence of new technology and personal data

Example:  
<https://www.engadget.com/ai/researchers-secretly-experimented-on-reddit-users-with-ai-generated-comments-194328026.html>

---

### 2. Load the notebook (5 minutes)

- Students open the Jupyter notebook
- Pair students without devices
- Instruct all to complete Section 0

---

### 3. Section 0 (20 minutes)

- Work through code/activities in Section 0
- Upon reaching the Screen Time activity, pause for a brief discussion to compare results

---

### 4. Section 1 (15 minutes)

- **2–3 min. explanation** of classification and course connections
- Students complete Section 1 at their own pace (**~15 min.**)

---

### 5. Sections 3–4 (20 minutes)

- Pause to discuss Section 1 findings in a group
- Students complete the remainder of the notebook

---

### 6. Takeaways and Activity (5–10 minutes)

- Time-dependent; includes:
    - Questions about methods
    - Brief lecture summarizing key takeaways
    - Begin participation activities (discussion posts, worksheets, etc.)

---

## Activity Materials

### Discussion Post Questions

Respond in **100–250 words** for each:

- How can sentiment analysis be useful in answering research questions? Can you think of any tasks it would be well suited to?
- Do you think the methods in the notebook were useful in understanding disinformation campaigns? What might be some of the limitations to these approaches?
- Discuss the role AI plays in disinformation, both the detection and analysis of it, and the production of it.

---

### Activity: Identify Disinformation Online

On a social media platform of your choice, try to identify a post you believe to be disinformation.  
You can search for specific topics or wait for something in your feed.  
**Link to the content here:** _______________________________________________________

1. **Why do you think this is disinformation?**  
   What data/information are you using from the content and its features to come to this conclusion?  
   Explain your reasoning in **150–300 words**.

2. **Compare with the Classifier:**  
   Think back to the classifier in the notebook.  
   What data was it using to classify text as disinformation?  
   Is that process similar or different from how you identified your post?  
   Do you think you are more likely to be correct? If so, why?  
   Respond in **200–350 words**.

---


## Modules

::: {#soci280}

:::


