{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7be9a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "page",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "era",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "1d4f2e98-4a09-404a-92ef-908b7782abe1",
       "rows": [
        [
         "0",
         "page184_img01_photo2.jpg",
         "184",
         "FORERUNNERS",
         "Before 615 BC"
        ],
        [
         "1",
         "page184_img01_photo3.jpg",
         "184",
         "FORERUNNERS",
         "Before 615 BC"
        ],
        [
         "2",
         "page184_img01_photo4.jpg",
         "184",
         "FORERUNNERS",
         "Before 615 BC"
        ],
        [
         "3",
         "page184_img01_photo6.jpg",
         "184",
         "FORERUNNERS",
         "Before 615 BC"
        ],
        [
         "4",
         "page184_img01_photo7.jpg",
         "184",
         "FORERUNNERS",
         "Before 615 BC"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>group</th>\n",
       "      <th>era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>page184_img01_photo2.jpg</td>\n",
       "      <td>184</td>\n",
       "      <td>FORERUNNERS</td>\n",
       "      <td>Before 615 BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>page184_img01_photo3.jpg</td>\n",
       "      <td>184</td>\n",
       "      <td>FORERUNNERS</td>\n",
       "      <td>Before 615 BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>page184_img01_photo4.jpg</td>\n",
       "      <td>184</td>\n",
       "      <td>FORERUNNERS</td>\n",
       "      <td>Before 615 BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>page184_img01_photo6.jpg</td>\n",
       "      <td>184</td>\n",
       "      <td>FORERUNNERS</td>\n",
       "      <td>Before 615 BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>page184_img01_photo7.jpg</td>\n",
       "      <td>184</td>\n",
       "      <td>FORERUNNERS</td>\n",
       "      <td>Before 615 BC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  page        group            era\n",
       "0  page184_img01_photo2.jpg   184  FORERUNNERS  Before 615 BC\n",
       "1  page184_img01_photo3.jpg   184  FORERUNNERS  Before 615 BC\n",
       "2  page184_img01_photo4.jpg   184  FORERUNNERS  Before 615 BC\n",
       "3  page184_img01_photo6.jpg   184  FORERUNNERS  Before 615 BC\n",
       "4  page184_img01_photo7.jpg   184  FORERUNNERS  Before 615 BC"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/sculpture_dataset_labeled.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import timm\n",
    "from tqdm.notebook import tqdm # Import tqdm for progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0485aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'convnextv2_tiny' \n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "model.eval()  # set to eval mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51686ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a1d28856a44a1797f2b9aa3e5b2514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Images in Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "embeddings = []\n",
    "\n",
    "image_directory = \"../data/richter_kouroi_filtered_photos\"\n",
    "\n",
    "# Collect filenames and eras for batching\n",
    "filenames = df['filename'].tolist()\n",
    "eras = df['era'].tolist()\n",
    "\n",
    "for i in tqdm(range(0, len(filenames), batch_size), desc=\"Processing Images in Batches\"):\n",
    "    batch_filenames = filenames[i:i + batch_size]\n",
    "\n",
    "    images = []\n",
    "    valid_indices = []\n",
    "    for j, filename in enumerate(batch_filenames):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')  # convert to RGB to avoid issues\n",
    "            images.append(image)\n",
    "            valid_indices.append(i + j)  # Keep track of valid indices for later\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found at: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {filename}: {e}\")\n",
    "\n",
    "    if len(images) == 0:\n",
    "        continue  # Skip empty batches\n",
    "\n",
    "    # Process the batch of images\n",
    "    inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # Mean pooling over patches per image in batch\n",
    "    batch_embeddings = last_hidden_states.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    # Append embeddings maintaining order corresponding to valid images\n",
    "    embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9ac239",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(embeddings)\n",
    "\n",
    "np.save('../data/embeddings/all_photos_embeddings.npy', embeddings)\n",
    "np.save('../data/embeddings/all_photos_eras.npy', eras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "994b4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5151515151515151\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = np.load('../data/embeddings/all_photos_embeddings.npy')\n",
    "y = np.load('../data/embeddings/all_photos_eras.npy')\n",
    "\n",
    "# X = embeddings, y = your labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1268b7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9470d7aeadee4e2d9e77247777657564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Images in Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/complete_sculpture_dataset_labeled.csv')\n",
    "\n",
    "batch_size = 32\n",
    "embeddings = []\n",
    "\n",
    "image_directory = \"../data/richter_kouroi_complete_front_only\"\n",
    "\n",
    "# Collect filenames and eras for batching\n",
    "filenames = df['filename'].tolist()\n",
    "eras = df['era'].tolist()\n",
    "material = df['material'].tolist()\n",
    "\n",
    "for i in tqdm(range(0, len(filenames), batch_size), desc=\"Processing Images in Batches\"):\n",
    "    batch_filenames = filenames[i:i + batch_size]\n",
    "\n",
    "    images = []\n",
    "    valid_indices = []\n",
    "    for j, filename in enumerate(batch_filenames):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')  # convert to RGB to avoid issues\n",
    "            images.append(image)\n",
    "            valid_indices.append(i + j)  # Keep track of valid indices for later\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found at: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {filename}: {e}\")\n",
    "\n",
    "    if len(images) == 0:\n",
    "        continue  # Skip empty batches\n",
    "\n",
    "    # Process the batch of images\n",
    "    inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # Mean pooling over patches per image in batch\n",
    "    batch_embeddings = last_hidden_states.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    # Append embeddings maintaining order corresponding to valid images\n",
    "    embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa87338",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(embeddings)\n",
    "\n",
    "np.save('../data/embeddings/complete_sculptures_embeddings.npy', embeddings)\n",
    "np.save('../data/embeddings/complete_sculptures_eras.npy', eras)\n",
    "np.save('../data/embeddings/complete_sculptures_material.npy', material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "717bdb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = embeddings\n",
    "y1 = eras\n",
    "y2 = material\n",
    "\n",
    "# X = embeddings, y = your labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a941c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ff8090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63ffb21039f421995fc47d84d721837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Images in Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/head_dataset_labeled.csv')\n",
    "\n",
    "batch_size = 32\n",
    "embeddings = []\n",
    "\n",
    "image_directory = \"../data/richter_kouroi_head_front_only\"\n",
    "\n",
    "# Collect filenames and eras for batching\n",
    "filenames = df['filename'].tolist()\n",
    "eras = df['era'].tolist()\n",
    "\n",
    "for i in tqdm(range(0, len(filenames), batch_size), desc=\"Processing Images in Batches\"):\n",
    "    batch_filenames = filenames[i:i + batch_size]\n",
    "\n",
    "    images = []\n",
    "    valid_indices = []\n",
    "    for j, filename in enumerate(batch_filenames):\n",
    "        image_path = os.path.join(image_directory, filename)\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')  # convert to RGB to avoid issues\n",
    "            images.append(image)\n",
    "            valid_indices.append(i + j)  # Keep track of valid indices for later\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Image not found at: {image_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {filename}: {e}\")\n",
    "\n",
    "    if len(images) == 0:\n",
    "        continue  # Skip empty batches\n",
    "\n",
    "    # Process the batch of images\n",
    "    inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # Mean pooling over patches per image in batch\n",
    "    batch_embeddings = last_hidden_states.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    # Append embeddings maintaining order corresponding to valid images\n",
    "    embeddings.extend(batch_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2002be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(embeddings)\n",
    "\n",
    "np.save('../data/embeddings/head_embeddings.npy', embeddings)\n",
    "np.save('../data/embeddings/head_eras.npy', eras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22edbe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "X = embeddings\n",
    "y1 = eras\n",
    "\n",
    "# X = embeddings, y = your labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032986e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
