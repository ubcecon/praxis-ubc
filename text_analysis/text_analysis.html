<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>text_analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="text_analysis_files/libs/clipboard/clipboard.min.js"></script>
<script src="text_analysis_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="text_analysis_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="text_analysis_files/libs/quarto-html/popper.min.js"></script>
<script src="text_analysis_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="text_analysis_files/libs/quarto-html/anchor.min.js"></script>
<link href="text_analysis_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="text_analysis_files/libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="text_analysis_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="text_analysis_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="text_analysis_files/libs/bootstrap/bootstrap-81267100e462c21b3d6c0d5bf76a3417.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="section-1-traditional-qualitative-coding" class="level2">
<h2 class="anchored" data-anchor-id="section-1-traditional-qualitative-coding">Section 1: Traditional qualitative coding</h2>
<p>The Coding Manual for Qualitative Researchers Qualitative Data: An Introduction to Coding and Analysis https://resources.nu.edu/c.php?g=1007180&amp;p=7392331</p>
<section id="examples-of-traditional-qualitative-coding-papers" class="level3">
<h3 class="anchored" data-anchor-id="examples-of-traditional-qualitative-coding-papers">1.1 Examples of traditional qualitative coding, papers</h3>
<p>A interactive NYT article would work nicely here. A lot of their research is qualitative coding voter preferences etc</p>
</section>
<section id="recent-updates" class="level3">
<h3 class="anchored" data-anchor-id="recent-updates">1.2 Recent updates</h3>
<p>https://www.mturk.com/ https://www.prolific.com/academic-researchers</p>
</section>
</section>
<section id="section-2-computational-text-analysis" class="level2">
<h2 class="anchored" data-anchor-id="section-2-computational-text-analysis">Section 2: Computational text analysis</h2>
<section id="supervised-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="supervised-machine-learning">2.1 Supervised machine learning</h3>
<p>Tokenization, Text Normalization, Stop Word Removal, TF-IDF (google it + show off the relevant python/R libraries) For R: - SnowballC - tidytext Python: - scikitlearn</p>
<section id="statistical-frameworks" class="level4">
<h4 class="anchored" data-anchor-id="statistical-frameworks">2.1.1 Statistical frameworks</h4>
<p>https://smltar.com/ Naive Bayes, Logistic Regression, SVMs - Show off R/python libraries for this</p>
</section>
<section id="deep-learning-frameworks" class="level4">
<h4 class="anchored" data-anchor-id="deep-learning-frameworks">2.1.2 Deep learning frameworks</h4>
<p>https://www.packtpub.com/en-us/product/getting-started-with-google-bert-9781838821593</p>
</section>
</section>
<section id="unsupervised-learning" class="level3">
<h3 class="anchored" data-anchor-id="unsupervised-learning">2.2 Unsupervised learning</h3>
<section id="topic-modelling" class="level4">
<h4 class="anchored" data-anchor-id="topic-modelling">2.2.1 Topic modelling</h4>
<ul>
<li>LDA Introduction to Topic Modeling and Text Classification, W.J.B. Mattingly</li>
</ul>
</section>
<section id="clustering" class="level4">
<h4 class="anchored" data-anchor-id="clustering">2.2.2 Clustering</h4>
<ul>
<li>K-means, Hierarchical Text Mining: Classification, Clustering, and Applications, Ashok N. Srivastava</li>
</ul>
</section>
<section id="embeddings-briefly" class="level4">
<h4 class="anchored" data-anchor-id="embeddings-briefly">2.2.3 Embeddings (briefly)</h4>
<ul>
<li>Word2Vec</li>
<li>Skip-Gram, CBOW Embeddings in Natural Language Processing: Theory and Advances in Vector Representations of Meaning</li>
</ul>
</section>
</section>
<section id="natural-language-processing-brief" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-processing-brief">2.3 Natural Language Processing (brief)</h3>
<p>Natural Language Processing (NLP) is a branch of artificial intelligence that enables computers to understand, interpret, and generate human language. By combining computational linguistics with machine learning and deep learning techniques, NLP allows machines to process language data, and reveal meaning.</p>
<section id="dependency-relationships" class="level4">
<h4 class="anchored" data-anchor-id="dependency-relationships">2.3.1 Dependency Relationships</h4>
<p>At the core of NLP is the concept of dependency. Dependency is the process to analyze the grammatical structure in a sentence and find related words as well as the type of relationship between them. Each word’s grammatical role—such as subject, verb, or object contributes to the overall structure of the sentence. For example, in the sentence “He bought a car.” The verb bought links all of the other words. He is the subject and the car is the object. Dependency parsing is the process by which these relationships are mapped out, creating a visual structure (called a parse tree) that makes the underlying grammatical links explicit. In computational linguistics and NLP, identifying these dependencies is fundamental for tasks like machine translation, question answering, and summarization.</p>
<p>An example of a parse tree for “He bought a new car.” <img src="media/parse_tree.png" class="img-fluid" alt="Parse Tree Example">.</p>
<p>These parse trees help explain meanings in complex sentences for the computer. They make a map of semantic meaning.</p>
</section>
<section id="named-entity-recognition-ner-object-detection" class="level4">
<h4 class="anchored" data-anchor-id="named-entity-recognition-ner-object-detection">2.3.2 Named Entity Recognition (NER) / Object Detection</h4>
<p>Named Entity Recognition (NER) is a technique in NLP that identifies and classifies named entities in text into predefined categories like person, organization, location, dates. A named entity is a real-world object that can be denoted with a proper name for instance: The University of British Columbia, Vancouver or August 20. “These categories can include, but are not limited to, names of individuals, organizations, locations, expressions of times, quantities, medical codes, monetary values and percentages, among others. Essentially, NER is the process of taking a string of text (i.e., a sentence, paragraph or entire document), and identifying and classifying the entities that refer to each category.” (IBM)</p>
<p>There are two steps in this process:</p>
<ol type="1">
<li>identifying the entity</li>
<li>categorizing it</li>
</ol>
<p>An example of this could be scanning a stock market report and extracting names of stocks and dates. Here is an example of NER working on an article</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="media/Named-Entity-Recognition.jpg" class="img-fluid figure-img"></p>
<figcaption>NER Example</figcaption>
</figure>
</div>
<p>The image above is from &lt;cogitotech.com&gt;.</p>
</section>
<section id="grammatical-parsing" class="level4">
<h4 class="anchored" data-anchor-id="grammatical-parsing">2.3.3 Grammatical Parsing</h4>
<p>Grammatical parsing in NLP is the process of examining the grammatical structure and relationships inside a given sentence or text. “It involves analyzing the text to determine the roles of specific words, such as nouns, verbs, and adjectives, as well as their interrelationships” (Intellipaat).</p>
<p>Rather than simply identifying individual words like in Named Entity Recognition, grammatical parsing uncovers how those words fit together. A significant part of this process is the parse tree from before, by constructing one of these the computer can gain an understanding of the structure.</p>
<p>One possible technique is Top-Down Parsing. It begins with the highest-level rule and works downward, recursively expanding each non-terminal symbol until the entire sentence is derived. This method tries to match the input sentence with the grammatical structures prescribed by the language’s rules, starting from the broadest abstraction and breaking it down into smaller, more concrete units.</p>
<p>Lets look at an example from Intellipaat with the sentance “John is playing a game” for this to work the parser already knows that <strong>Sentence = S = Noun Phrase (NP) + Verb Phrase (VP) + Preposition Phrase (PP)</strong> is a valid grammatical form in English.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="media/top_down_parsing.png" class="img-fluid figure-img"></p>
<figcaption>Example of Top Down Parsing</figcaption>
</figure>
</div>
<p>In the image above the Top-Down Parser looks through identifing that John is a noun then moves back up and examines the next word until it finally reaches a full sentence structure.</p>
</section>
</section>
<section id="recent-updates-1" class="level3">
<h3 class="anchored" data-anchor-id="recent-updates-1">2.4 Recent Updates</h3>
<section id="learning-goals-23-minutes" class="level6">
<h6 class="anchored" data-anchor-id="learning-goals-23-minutes">Learning goals (2–3 minutes)</h6>
<ul>
<li>Understand <strong>what NLI is</strong> and how it enables <strong>zero-shot</strong> labeling</li>
<li>Differentiate <strong>encoder</strong> vs <strong>decoder</strong> style models at a glance</li>
<li>Know the four <strong>modern workflows</strong>: zero-shot, few-shot, <strong>RAG</strong>, fine-tuning</li>
<li>Grasp <strong>privacy trade-offs</strong>: APIs, chat, local vs.&nbsp;cloud</li>
</ul>
<!-- Presenter note:
Keep this short: “We’re covering concepts only. Think ‘what exists and why it matters.’”
-->
</section>
<section id="natural-language-inference-nli-and-zero-shot-learning" class="level4">
<h4 class="anchored" data-anchor-id="natural-language-inference-nli-and-zero-shot-learning">2.4.1 Natural Language Inference (NLI) and Zero-Shot Learning</h4>
<section id="what-is-natural-language-inference-nli" class="level6">
<h6 class="anchored" data-anchor-id="what-is-natural-language-inference-nli">What is Natural Language Inference (NLI)?</h6>
<p>Natural Language Inference (NLI) is a task where a model is given two sentences and must decide if the second sentence makes sense based on the first.</p>
<p>Think of a student passing an exam on a subject they’ve never really studied before. That works because humans generalize from what they know. Zero-Shot Learning (ZSL) lets models do the same — applying knowledge to new tasks without ever seeing examples. <a href="https://medium.com/@asanchezyali/zero-shot-text-classification-c737db000005">Zero-Shot Text Classification</a></p>
<ul>
<li><strong>Premise</strong> = the original statement.<br>
</li>
<li><strong>Hypothesis</strong> = the statement we want to check against the premise.</li>
</ul>
<p>The model has to choose between three possibilities:<br>
1. <strong>Entailment (Yes)</strong> — the hypothesis fits with the premise.<br>
2. <strong>Contradiction (No)</strong> — the hypothesis clashes with the premise.<br>
3. <strong>Neutral (Maybe)</strong> — there isn’t enough information to decide.</p>
<p><strong>Example</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 21%">
<col style="width: 16%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="header">
<th>Premise</th>
<th>Hypothesis</th>
<th>Answer Type</th>
<th>Why?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A man is riding a bicycle.</td>
<td>A man is outdoors.</td>
<td><strong>Entailment (Yes)</strong></td>
<td>Riding a bike usually implies being outside.</td>
</tr>
<tr class="even">
<td>A man is riding a bicycle.</td>
<td>A man is swimming.</td>
<td><strong>Contradiction (No)</strong></td>
<td>You cannot ride a bike and swim at the same time.</td>
</tr>
<tr class="odd">
<td>A man is riding a bicycle.</td>
<td>The man is wearing a helmet.</td>
<td><strong>Neutral (Maybe)</strong></td>
<td>The premise doesn’t tell us if he is wearing a helmet.</td>
</tr>
</tbody>
</table>
<p>This is important because it shows the model isn’t just matching words, it’s making an <strong>inference about meaning (reasoning)</strong>.</p>
<hr>
</section>
<section id="from-nli-to-zero-shot-learning" class="level6">
<h6 class="anchored" data-anchor-id="from-nli-to-zero-shot-learning">From NLI to Zero-Shot Learning</h6>
<p>Now imagine this: A student is able to pass an exam on a subject they’ve never studied. They do it by <strong>generalizing</strong> knowledge from other subjects.</p>
<p>Zero-Shot Learning (ZSL) works the same way for AI. Instead of needing thousands of training examples for a task, we can reframe classification as an NLI problem:</p>
<ul>
<li>The <strong>premise</strong> is the text we want to classify.<br>
</li>
<li>The <strong>hypotheses</strong> are the possible labels, rewritten as simple sentences.
<ul>
<li>Example: <em>“This review is positive.”</em>, <em>“This review is negative.”</em>, <em>“This review is neutral.”</em></li>
</ul></li>
</ul>
<p>The model then tests: <em>Does the premise support this hypothesis?</em> The one that fits best is then chosen as the label.</p>
<p><strong>Example</strong><br>
- Premise: <em>“The café’s coffee is absolutely amazing!”</em><br>
- Hypotheses:<br>
1. <em>“This review is positive.”</em><br>
2. <em>“This review is negative.”</em><br>
3. <em>“This review is neutral.”</em><br>
- Model’s answer: <strong>Positive</strong> — no labeled training data required.</p>
<hr>
</section>
<section id="why-zero-shot-matters" class="level6">
<h6 class="anchored" data-anchor-id="why-zero-shot-matters">Why Zero-Shot Matters</h6>
<p>For a long time, supervised machine learning required building large, carefully labeled datasets before a model could classify text. You had to teach the student (the model) before it could pass the exam. This was expensive and time-consuming.</p>
<p>With NLI-based zero-shot methods, we can:<br>
- <strong>Scale</strong> human codebooks or categories across very large corpus.<br>
- <strong>Prototype quickly</strong> test out categories before committing to labeling thousands of documents.<br>
- <strong>Explore free-text responses</strong> in surveys or interviews without heavy preprocessing. You don’t need to read an entire review to tell the customer is unhappy.</p>
<p>These methods are powered by <strong>encoder-only transformers (models designed mainly to read text)</strong> like BERT, RoBERTa, and DeBERTa, which are strong at understanding relationships between sentences.</p>
<ul>
<li><strong>Before ~2020</strong> Zero-shot classification was rare because a lot of labeled data was needed.<br>
</li>
<li><strong>Now</strong> With strong NLI models, we can classify text cheaply and effectively even without training data (teaching the model).</li>
</ul>
<p><strong>Applications</strong><br>
- Auto-tagging and organizing large collections of documents<br>
- Moderating harmful or misleading content<br>
- Routing customer service tickets to the right team<br>
- Rapidly scanning survey responses to detect themes</p>
</section>
<section id="beyond-text-zero-shot-in-vision" class="level6">
<h6 class="anchored" data-anchor-id="beyond-text-zero-shot-in-vision">Beyond Text: Zero-Shot in Vision</h6>
<p>Zero-shot learning is not just for text. Vision-language systems combine images and text in the same “meaning space.” This allows a model to classify <strong>images it has never seen before</strong> using natural-language descriptions.</p>
<p>For example, given a new photo of an animal, the model can choose between descriptions like <em>“a photo of a zebra”</em> or <em>“a photo of a horse”</em> — even if “zebra” was never explicitly labeled in its training data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="media/NLI_Image_classification.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
</section>
<section id="classification-and-discovery-using-decoder-only-models" class="level4">
<h4 class="anchored" data-anchor-id="classification-and-discovery-using-decoder-only-models">2.4.2 Classification and discovery using decoder only models</h4>
<p><strong>What are they?</strong><br>
Decoder-only transformers (pattern matchers like GPT) generate text one word at a time. With the right prompts, they can <strong>classify, summarize, or find patterns</strong>.</p>
<p><strong>Why it matters</strong><br>
- Works without special training for many tasks.<br>
- Lets us explore and scale categories quickly.<br>
- Used in most modern chatbots and APIs (ChatGPT, Claude, LLaMA, etc.).</p>
<section id="using-these-models-in-practice" class="level6">
<h6 class="anchored" data-anchor-id="using-these-models-in-practice">Using these models in practice</h6>
<p><strong>APIs vs.&nbsp;Chat</strong><br>
- <em>APIs</em>: They allow you to connect the model to your own system. Good for automation.<br>
- <em>Chat UIs</em>: Easy to use and quick. Good for testing ideas.</p>
<p><strong>Local vs.&nbsp;Cloud</strong><br>
- <em>Local</em>: data stays private; needs hardware. - <em>Cloud</em>: easy access; data leaves your system.</p>
<p><strong>Applications</strong><br>
- Auto-tagging document and moderating text<br>
- Detecting customers intent in messages<br>
- Drafting summaries and themes</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Watch outs</strong> - Models can “hallucinate” (make things up). - Results depend on how you phrase the prompt. - Privacy risks if data leaves your system. - Costs add up if used at scale.</p>
</div>
</div>
</section>
<section id="four-ways-to-guide-large-language-models" class="level5">
<h5 class="anchored" data-anchor-id="four-ways-to-guide-large-language-models">2.4.2.1 Four Ways to Guide Large Language Models</h5>
<p>There are <strong>four main ways</strong> we can get large language models (LLMs) to handle classification or generation tasks. They range from the simplest, asking the model directly (such as when we generally ChatGPT), to the most advanced — retraining it on your own data (teaching a model).</p>
<ol type="1">
<li><p><strong>Zero-shot</strong><br>
Ask the model directly. No training data.<br>
<em>Example:</em> “Classify this as positive or negative.”</p></li>
<li><p><strong>Few-shot</strong><br>
Add a handful of examples to guide the model.<br>
<em>Example:</em> Show 3 labeled reviews, then give it a new one.</p></li>
<li><p><strong>RAG (Retrieval-Augmented Generation)</strong><br>
Model looks up facts from your own documents and uses what it already knows.<br>
<em>Why:</em> reduces “hallucinations” and keeps answers grounded.</p></li>
</ol>
<p><strong>Fine-tuning</strong><br>
Retrain the model on your data (eg. specialising in Legal text)<br>
<em>Best for:</em> consistent style, domain knowledge, large-scale use.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Think of it as a ladder:<br>
Start with <strong>zero-shot</strong>, move up to <strong>few-shot</strong>, then <strong>RAG</strong>, and finally <strong>fine-tuning</strong>.Each step gives the model more guidance</p>
</div>
</div>
</section>
<section id="llms-apis-vs.-chat-based-interfaces" class="level5">
<h5 class="anchored" data-anchor-id="llms-apis-vs.-chat-based-interfaces">2.4.2.2 LLMs: APIs vs.&nbsp;Chat-Based Interfaces</h5>
<p>LLMs can be used in <strong>two main ways</strong>:<br>
1. <strong>APIs</strong> to connect the model into your own systems.<br>
2. <strong>Chat-based interfaces</strong> interact directly through a conversational window.</p>
<p>Both have strengths and weaknesses, depening on its application.</p>
<section id="apis-application-programming-interfaces" class="level6">
<h6 class="anchored" data-anchor-id="apis-application-programming-interfaces">APIs (Application Programming Interfaces)</h6>
<p><strong>What it is</strong><br>
Think of an API as a “pipeline.” You send text to the model in the background, and it sends a response back. There is no chat window, it runs quietly inside your systems.</p>
<p><strong>Strengths</strong><br>
- Its great for <strong>automation</strong> (batch jobs, workflows, scheduled tasks).<br>
- Can <strong>integrate with existing apps</strong> (e.g., surveys, chatbots, customer support).<br>
- Scales to handle <strong>large datasets</strong> consistently.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Use Case: Surveys with APIs</strong></p>
<p>Imagine a company that collects short surveys at the end of every sale. They want to know if customers felt the process was <strong>easy</strong> or <strong>confusing</strong>.</p>
<p>Instead of hiring someone to read through thousands of responses, the system sends each survey to an <strong>API</strong>. The LLM quickly classifies the answers into categories, and the company gets a clear report — all done automatically in the background.</p>
</div>
</div>
<p><strong>Limitations</strong><br>
- Needs <strong>technical setup</strong> (developers, coding, integration).<br>
- Not designed for <strong>interactive exploration</strong> — you don’t “chat,” you send structured requests, usually in the form of code.</p>
<hr>
</section>
<section id="chat-based-interfaces" class="level6">
<h6 class="anchored" data-anchor-id="chat-based-interfaces">Chat-Based Interfaces</h6>
<p><strong>What it is</strong><br>
This is the familiar <strong>conversational window</strong> — you type, the model replies.</p>
<p><strong>Strengths</strong><br>
- Extremely <strong>intuitive</strong> — no setup required.<br>
- Perfect for <strong>brainstorming, Q&amp;A, and demos</strong>.<br>
- Great for <strong>quick experiments</strong> when you want to test an idea on the fly.</p>
<p><strong>Limitations</strong><br>
- Harder to <strong>scale or automate</strong> (each interaction is manual).<br>
- Answers may be <strong>less consistent</strong> in formatting compared to API outputs.</p>
<hr>
</section>
<section id="why-this-matters-at-a-glance" class="level6">
<h6 class="anchored" data-anchor-id="why-this-matters-at-a-glance">Why This Matters (At a Glance)</h6>
<ul>
<li><strong>APIs</strong> = best for <em>quiet, large-scale automation and production systems</em>.<br>
</li>
<li><strong>Chat</strong> = best for <em>human-in-the-loop exploration and design</em>.</li>
</ul>
<p>In practice, most teams combine both approaches:<br>
- Use <strong>Chat interfaces</strong> for prototyping and developing ideas.<br>
- Use <strong>APIs</strong> for scaling those ideas into production pipelines.</p>
</section>
</section>
<section id="local-models-vs.-sending-data-to-a-company-brief" class="level5">
<h5 class="anchored" data-anchor-id="local-models-vs.-sending-data-to-a-company-brief">2.4.2.3 Local models vs.&nbsp;sending data to a company (brief)</h5>
<p><strong>The choice:</strong><br>
Do you run the model <strong>on your own machine (local)</strong>, or do you <strong>send data to a company’s servers (cloud/hosted APIs)</strong>?</p>
<hr>
<section id="local-models" class="level6">
<h6 class="anchored" data-anchor-id="local-models">Local Models</h6>
<ul>
<li>Data stays in your own environment, so you have more <strong>privacy &amp; control</strong>.<br>
</li>
<li>No outside company sees your text.<br>
</li>
<li>Good for sensitive data (health, finance, legal).<br>
</li>
<li>Downsides: needs <strong>hardware (GPUs, storage)</strong> and technical setup.</li>
</ul>
<hr>
</section>
<section id="cloud-hosted-apis" class="level6">
<h6 class="anchored" data-anchor-id="cloud-hosted-apis">Cloud / Hosted APIs</h6>
<ul>
<li>Example: OpenAI, Anthropic, Google, Microsoft.<br>
</li>
<li><strong>Fast start, easy to use</strong>; no setup needed.<br>
</li>
<li>Access to <strong>state-of-the-art</strong> models.<br>
</li>
<li>Downsides: data leaves your system, subject to <strong>company policies</strong>.<br>
</li>
<li>Pay per use; can be expensive at scale.</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Cost Watch: APIs at Scale</strong> API pricing typically depends on how many <em>tokens</em> (pieces of text) you send and receive. For example:</p>
<ul>
<li><strong>GPT-4.5</strong> costs about <strong>$75 per 1 million input tokens</strong> and <strong>$150 per 1 million output tokens</strong>.</li>
</ul>
<p><strong>Scenario:</strong> If a company processes <strong>10,000 reviews/day</strong>, each 100 input + 50 output tokens:</p>
<ul>
<li>With GPT-4.5:
<ul>
<li>Input cost = (10,000 × 100) / 1M × $75 ≈ <strong>$75</strong><br>
</li>
<li>Output cost = (10,000 × 50) / 1M × $150 ≈ <strong>$75</strong><br>
</li>
<li><strong>Total ≈ $150/day → ~$4,500/month</strong></li>
</ul></li>
</ul>
</div>
</div>
<hr>
</section>
<section id="quick-comparison" class="level6">
<h6 class="anchored" data-anchor-id="quick-comparison">Quick Comparison</h6>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Local Models</th>
<th>Cloud/Hosted APIs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Privacy &amp; control</td>
<td>Easy &amp; instant access</td>
</tr>
<tr class="even">
<td>Needs hardware setup</td>
<td>No setup needed</td>
</tr>
<tr class="odd">
<td>Good for sensitive data</td>
<td>Best models available</td>
</tr>
<tr class="even">
<td>Higher upfront effort</td>
<td>Ongoing usage costs</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Rule of thumb:</strong><br>
- If privacy is critical use a <strong>local model</strong>.<br>
- If speed &amp; cutting-edge accuracy matter use <strong>cloud APIs</strong>.</p>
</div>
</div>
<hr>
</section>
</section>
</section>
</section>
<section id="ai-ethics" class="level3">
<h3 class="anchored" data-anchor-id="ai-ethics">2.5 AI ethics</h3>
</section>
<section id="sources" class="level3">
<h3 class="anchored" data-anchor-id="sources">2.6 Sources</h3>
<p>From Section 2.3 - https://www.ibm.com/think/topics/natural-language-processing - https://aws.amazon.com/what-is/nlp/ - https://towardsdatascience.com/natural-language-processing-dependency-parsing-cf094bbbe3f7/ - https://www.ibm.com/think/topics/named-entity-recognition - https://lincsproject.ca/docs/terms/named-entity-recognition - https://intellipaat.com/blog/what-is-parsing-in-nlp/ - https://www.cogitotech.com/natural-language-processing/named-entity-recognition/ From Section 2.4 - Yali Sánchez, <em>Zero-Shot Text Classification</em> — <a href="https://medium.com/@asanchezyali/zero-shot-text-classification-c737db000005">Medium article</a><br>
- Modulai Blog: <em>Zero-Shot Learning in NLP</em> — <a href="https://modulai.io/blog/zero-shot-learning-in-nlp/" class="uri">https://modulai.io/blog/zero-shot-learning-in-nlp/</a><br>
- Wikipedia: <em>Zero-shot learning</em> — <a href="https://en.wikipedia.org/wiki/Zero-shot_learning" class="uri">https://en.wikipedia.org/wiki/Zero-shot_learning</a></p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>